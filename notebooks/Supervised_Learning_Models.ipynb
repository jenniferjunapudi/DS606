{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86b3b4a2-ff5b-47ec-abcd-98c1121d1a72",
   "metadata": {},
   "source": [
    "IMPORTING PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1faf8a9-ca26-4d42-a098-857b2ebf90db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql import DataFrame\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import (\n",
    "    min, max, col, isnan, isnull, \n",
    ")\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.ml.stat import Correlation\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler, MinMaxScaler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e350b529-6f94-413a-ad88-6c4a5c337f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\june3\\OneDrive\\Desktop\\my_output_result\n"
     ]
    }
   ],
   "source": [
    "# Changing the directory to a specific location\n",
    "%cd C:\\Users\\june3\\OneDrive\\Desktop\\my_output_result\\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a639ca-949e-4410-88d5-f18cd4339ec7",
   "metadata": {},
   "source": [
    "CREATE SPARK SESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88f5cdb7-7e3b-4803-ac9c-d0e19c4e1d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SDWA DATA ANALYSIS 2\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f4109e3-5906-414c-9070-1f6af0fac2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Read all CSV files into a Spark DataFrame\n",
    "df = spark.read.csv(\"gmm_k5.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a5b3dea-814d-4181-b48a-2cac08760a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster_mapping = {0: 'High-Risk', \n",
    "#                    1: 'Low-Risk', \n",
    "#                    2: 'Moderate-Risk', \n",
    "#                    3: 'Near-Compliant', \n",
    "#                    4: 'Compliant'}\n",
    "\n",
    "# mapping_expr = F.create_map([F.lit(x) for pair in cluster_mapping.items() for x in pair])\n",
    "# df = df.withColumn('label', mapping_expr[df['cluster']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1cf03d9-927b-473d-8e3d-1d2572c42f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the relevant columns\n",
    "df = df.select(\"PWSID\", \n",
    "            \"PWS_ACTIVITY_CODE\", \n",
    "            \"IS_SCHOOL_OR_DAYCARE_IND\",\n",
    "            \"SOURCE_WATER_PROTECTION_CODE\", \n",
    "            \"OUTSTANDING_PERFORMER\",\n",
    "            \"MANAGEMENT_OPS_EVAL_CODE\",\n",
    "            \"SOURCE_WATER_EVAL_CODE\",\n",
    "            \"SECURITY_EVAL_CODE\",\n",
    "            \"PUMPS_EVAL_CODE\",\n",
    "            \"OTHER_EVAL_CODE\",\n",
    "            \"COMPLIANCE_EVAL_CODE\",\n",
    "            \"DATA_VERIFICATION_EVAL_CODE\",\n",
    "            \"TREATMENT_EVAL_CODE\",\n",
    "            \"FINISHED_WATER_STOR_EVAL_CODE\",\n",
    "            \"DISTRIBUTION_EVAL_CODE\",\n",
    "            \"FINANCIAL_EVAL_CODE\",\n",
    "            \"VIOLATION_CATEGORY_CODE\",\n",
    "            \"IS_HEALTH_BASED_IND\",\n",
    "            \"IS_MAJOR_VIOL_IND\",\n",
    "            \"VIOLATION_STATUS\",\n",
    "            \"ENF_ACTION_CATEGORY\",\n",
    "           \"COMPLIANCE_STATUS\",\n",
    "            \"TOTAL_POPULATION_SERVED_COUNT_LOG\",\n",
    "            \"TOTAL_SERVICE_CONNECTIONS_COUNT_LOG\",\n",
    "            \"VIOL_MEASURE_LOG\",\n",
    "            \"TOTAL_VIOLATIONS_LOG\",\n",
    "            \"AVG_VIOLATION_DURATION_DAYS_LOG\",\n",
    "            \"OPEN_VIOLATIONS_COUNT_LOG\",\n",
    "            \"TOTAL_LATE_COMPLIANT_ACTIONS_LOG\",\n",
    "            \"cluster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a2b034a-1e48-4040-9688-c3d9a8826e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to find the missing values\n",
    "def get_missing_values(df, dataframe_name):\n",
    "    # Compute missing values for each column\n",
    "    missing_df = df.select([\n",
    "        count(when(isnull(c) | isnan(c), c)).alias(c) for c in df.columns\n",
    "    ])\n",
    "    \n",
    "    # Convert to Pandas for better formatting\n",
    "    missing = missing_df.toPandas().transpose().reset_index()\n",
    "    missing.columns = ['Column', 'Missing_Count']\n",
    "    \n",
    "    # Display the missing values\n",
    "    print(f\"--- Missing Values in {dataframe_name} ---\")\n",
    "    print(missing.to_markdown(index=False))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb7c92fa-f646-4637-8181-cb8dad4a5cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Missing Values in Dataframe ---\n",
      "| Column                              |   Missing_Count |\n",
      "|:------------------------------------|----------------:|\n",
      "| PWSID                               |               0 |\n",
      "| PWS_ACTIVITY_CODE                   |               0 |\n",
      "| IS_SCHOOL_OR_DAYCARE_IND            |               0 |\n",
      "| SOURCE_WATER_PROTECTION_CODE        |               0 |\n",
      "| OUTSTANDING_PERFORMER               |               0 |\n",
      "| MANAGEMENT_OPS_EVAL_CODE            |               0 |\n",
      "| SOURCE_WATER_EVAL_CODE              |               0 |\n",
      "| SECURITY_EVAL_CODE                  |               0 |\n",
      "| PUMPS_EVAL_CODE                     |               0 |\n",
      "| OTHER_EVAL_CODE                     |               0 |\n",
      "| COMPLIANCE_EVAL_CODE                |               0 |\n",
      "| DATA_VERIFICATION_EVAL_CODE         |               0 |\n",
      "| TREATMENT_EVAL_CODE                 |               0 |\n",
      "| FINISHED_WATER_STOR_EVAL_CODE       |               0 |\n",
      "| DISTRIBUTION_EVAL_CODE              |               0 |\n",
      "| FINANCIAL_EVAL_CODE                 |               0 |\n",
      "| VIOLATION_CATEGORY_CODE             |               0 |\n",
      "| IS_HEALTH_BASED_IND                 |               0 |\n",
      "| IS_MAJOR_VIOL_IND                   |               0 |\n",
      "| VIOLATION_STATUS                    |               0 |\n",
      "| ENF_ACTION_CATEGORY                 |               0 |\n",
      "| COMPLIANCE_STATUS                   |               0 |\n",
      "| TOTAL_POPULATION_SERVED_COUNT_LOG   |               0 |\n",
      "| TOTAL_SERVICE_CONNECTIONS_COUNT_LOG |               0 |\n",
      "| VIOL_MEASURE_LOG                    |               0 |\n",
      "| TOTAL_VIOLATIONS_LOG                |               0 |\n",
      "| AVG_VIOLATION_DURATION_DAYS_LOG     |               0 |\n",
      "| OPEN_VIOLATIONS_COUNT_LOG           |               0 |\n",
      "| TOTAL_LATE_COMPLIANT_ACTIONS_LOG    |               0 |\n",
      "| cluster                             |               0 |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the missing values\n",
    "get_missing_values(df, \"Dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a107fe9f-621f-405a-b7a5-07ae825fc6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dataframe 1: rows: 43073, columns: 30 \n"
     ]
    }
   ],
   "source": [
    "# Display the Dataframe shape\n",
    "print(f\" Dataframe 1: rows: {df.count()}, columns: {len(df.columns)} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b998f003-d9a7-4fd9-bacf-cee56c7a2f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing the Categorical values into a variable\n",
    "cat_vars = [\"PWS_ACTIVITY_CODE\", \n",
    "            \"IS_SCHOOL_OR_DAYCARE_IND\",\n",
    "            \"SOURCE_WATER_PROTECTION_CODE\", \n",
    "            \"OUTSTANDING_PERFORMER\",\n",
    "            \"MANAGEMENT_OPS_EVAL_CODE\",\n",
    "            \"SOURCE_WATER_EVAL_CODE\",\n",
    "            \"SECURITY_EVAL_CODE\",\n",
    "            \"PUMPS_EVAL_CODE\",\n",
    "            \"OTHER_EVAL_CODE\",\n",
    "            \"COMPLIANCE_EVAL_CODE\",\n",
    "            \"DATA_VERIFICATION_EVAL_CODE\",\n",
    "            \"TREATMENT_EVAL_CODE\",\n",
    "            \"FINISHED_WATER_STOR_EVAL_CODE\",\n",
    "            \"DISTRIBUTION_EVAL_CODE\",\n",
    "            \"FINANCIAL_EVAL_CODE\",\n",
    "            \"VIOLATION_CATEGORY_CODE\",\n",
    "            \"IS_HEALTH_BASED_IND\",\n",
    "            \"IS_MAJOR_VIOL_IND\",\n",
    "            \"VIOLATION_STATUS\",\n",
    "            \"ENF_ACTION_CATEGORY\",\n",
    "           \"COMPLIANCE_STATUS\",\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6011115c-f95d-49f8-817b-bb5b8404a3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing the Numerical values into a variable\n",
    "num_vars = [\"TOTAL_POPULATION_SERVED_COUNT_LOG\",\n",
    "            \"TOTAL_SERVICE_CONNECTIONS_COUNT_LOG\",\n",
    "            \"VIOL_MEASURE_LOG\",\n",
    "            \"TOTAL_VIOLATIONS_LOG\",\n",
    "            \"AVG_VIOLATION_DURATION_DAYS_LOG\",\n",
    "            \"OPEN_VIOLATIONS_COUNT_LOG\",\n",
    "            \"TOTAL_LATE_COMPLIANT_ACTIONS_LOG\",\n",
    "           ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8724c65-5ebc-423a-83d8-cb86f06e6890",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a42be759-232f-41e1-91af-31482473fc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline stages\n",
    "stages = []\n",
    "\n",
    "# Step 1: Process categorical variables\n",
    "for col in cat_vars:\n",
    "    # StringIndexer for categorical variable\n",
    "    indexer = StringIndexer(inputCol=col, outputCol=f\"{col}_indexed\")\n",
    "    stages.append(indexer)\n",
    "\n",
    "    # OneHotEncoder for indexed variable\n",
    "    encoder = OneHotEncoder(inputCol=f\"{col}_indexed\", outputCol=f\"{col}_encoded\")\n",
    "    stages.append(encoder)\n",
    "\n",
    "# Step 2: Combine all encoded categorical and numerical columns using VectorAssembler\n",
    "# Collect encoded categorical columns and add numerical columns\n",
    "assembled_input_cols = [f\"{col}_encoded\" for col in cat_vars] + num_vars\n",
    "\n",
    "assembler = VectorAssembler(inputCols=assembled_input_cols, outputCol=\"features\")\n",
    "stages.append(assembler)\n",
    "\n",
    "# Step 3: Create the pipeline\n",
    "pipeline = Pipeline(stages=stages)\n",
    "\n",
    "# Fit and transform the data\n",
    "final_df = pipeline.fit(df).transform(df)\n",
    "\n",
    "# final_df will have a \"features\" column with all categorical and numerical variables combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7830a39b-ca39-401a-a605-3066f184b4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the feature vector using StandardScaler\n",
    "scaler1 = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withMean=True, withStd=True)\n",
    "scaler_model1 = scaler1.fit(final_df)\n",
    "scaled_data1 = scaler_model1.transform(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c006acdd-3fe6-4cc8-8e32-1bef51af592c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the feature vector using MinMaxScaler\n",
    "scaler2 = MinMaxScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n",
    "scaler_model2 = scaler2.fit(final_df)\n",
    "scaled_data2 = scaler_model2.transform(final_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e768044-247c-4f53-80f7-9bd141b5c857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets (70% training, 30% testing)\n",
    "train_data, test_data = scaled_data1.randomSplit([0.7, 0.3], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36c03e09-6649-4cbc-bbce-207450685a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets (70% training, 30% testing)\n",
    "trainData, testData = scaled_data2.randomSplit([0.7, 0.3], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaab532-d821-4d3f-aef6-1ffb814a025c",
   "metadata": {},
   "source": [
    "### Supervised Machine Learning Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80f75e9-6b19-42ce-ab30-f779f69add64",
   "metadata": {},
   "source": [
    "MULTINOMIAL LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc74a59c-38a4-4c8e-afec-ce880bdd3ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Multinomial Logistic Regression Model: 0.9728072933039924\n",
      "F1-Score of Multinomial Logistic Regression Model: 0.9722223615356852\n"
     ]
    }
   ],
   "source": [
    "# Initialize Multinomial Logistic Regression model\n",
    "lr = LogisticRegression(featuresCol=\"scaled_features\", labelCol=\"cluster\", family=\"multinomial\", maxIter=10)\n",
    "\n",
    "# Train the Multinomial Logistic Regression model\n",
    "lr_model = lr.fit(train_data)\n",
    "\n",
    "# Make predictions on test data\n",
    "lr_predictions = lr_model.transform(test_data)\n",
    "\n",
    "# Evaluate the model using accuracy\n",
    "lr_evaluator = MulticlassClassificationEvaluator(labelCol=\"cluster\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "lr_accuracy = lr_evaluator.evaluate(lr_predictions)\n",
    "print(f\"Accuracy of Multinomial Logistic Regression Model: {lr_accuracy}\")\n",
    "\n",
    "\n",
    "f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"cluster\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1_score = f1_evaluator.evaluate(lr_predictions)\n",
    "print(f\"F1-Score of Multinomial Logistic Regression Model: {f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "74a1538f-e53c-4dba-9703-04fe74a1652c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lr_trainingSummary = lr_model.summary\n",
    "lr_data = {\n",
    "    \"Label\": list(range(len(lr_trainingSummary.falsePositiveRateByLabel))),\n",
    "    \"False Positive Rate\": lr_trainingSummary.falsePositiveRateByLabel,\n",
    "    \"True Positive Rate\": lr_trainingSummary.truePositiveRateByLabel,\n",
    "    \"Precision\": lr_trainingSummary.precisionByLabel,\n",
    "    \"Recall\": lr_trainingSummary.recallByLabel,\n",
    "    \"F-Measure\": lr_trainingSummary.fMeasureByLabel(),\n",
    "}\n",
    "\n",
    "# Create a DataFrame for the per-label metrics\n",
    "lr_metrics_df = pd.DataFrame(lr_data)\n",
    "\n",
    "# Add overall metrics as a separate row\n",
    "overall_lr_metrics = pd.DataFrame([{\n",
    "    \"Label\": \"Overall\",\n",
    "    \"False Positive Rate\": lr_trainingSummary.weightedFalsePositiveRate,\n",
    "    \"True Positive Rate\": lr_trainingSummary.weightedTruePositiveRate,\n",
    "    \"Precision\": lr_trainingSummary.weightedPrecision,\n",
    "    \"Recall\": lr_trainingSummary.weightedRecall,\n",
    "    \"F-Measure\": lr_trainingSummary.weightedFMeasure(),\n",
    "}])\n",
    "\n",
    "# Combine the two DataFrames using pd.concat()\n",
    "lr_metrics_df = pd.concat([lr_metrics_df, overall_lr_metrics], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "12bbe34b-88a4-4b8d-a786-e86c4c8dc489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>True Positive Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F-Measure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001559</td>\n",
       "      <td>0.753555</td>\n",
       "      <td>0.932551</td>\n",
       "      <td>0.753555</td>\n",
       "      <td>0.833552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.005448</td>\n",
       "      <td>0.986075</td>\n",
       "      <td>0.975032</td>\n",
       "      <td>0.986075</td>\n",
       "      <td>0.980522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.020755</td>\n",
       "      <td>0.999815</td>\n",
       "      <td>0.982266</td>\n",
       "      <td>0.999815</td>\n",
       "      <td>0.990963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.009493</td>\n",
       "      <td>0.910203</td>\n",
       "      <td>0.950536</td>\n",
       "      <td>0.910203</td>\n",
       "      <td>0.929932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.003959</td>\n",
       "      <td>0.970567</td>\n",
       "      <td>0.961701</td>\n",
       "      <td>0.970567</td>\n",
       "      <td>0.966114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Overall</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.972849</td>\n",
       "      <td>0.972391</td>\n",
       "      <td>0.972849</td>\n",
       "      <td>0.972234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label  False Positive Rate  True Positive Rate  Precision    Recall  \\\n",
       "0        0             0.001559            0.753555   0.932551  0.753555   \n",
       "1        1             0.005448            0.986075   0.975032  0.986075   \n",
       "2        2             0.020755            0.999815   0.982266  0.999815   \n",
       "3        3             0.009493            0.910203   0.950536  0.910203   \n",
       "4        4             0.003959            0.970567   0.961701  0.970567   \n",
       "5  Overall             0.014064            0.972849   0.972391  0.972849   \n",
       "\n",
       "   F-Measure  \n",
       "0   0.833552  \n",
       "1   0.980522  \n",
       "2   0.990963  \n",
       "3   0.929932  \n",
       "4   0.966114  \n",
       "5   0.972234  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d382fbfa-19e0-415c-821b-2e3c23eedc29",
   "metadata": {},
   "source": [
    "RANDOM FOREST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "feade112-e84a-492f-8d1c-56fccdf2df5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest Classifier: 0.885020433825841\n",
      "Test Error for Random Forest Classifier = 0.11498\n"
     ]
    }
   ],
   "source": [
    "# Initialize the RandomForestClassifier\n",
    "rf = RandomForestClassifier(labelCol=\"cluster\", featuresCol=\"scaled_features\", numTrees=100)\n",
    "\n",
    "# Train the model\n",
    "rf_model = rf.fit(train_data)\n",
    "\n",
    "# Make predictions on the test set\n",
    "rf_predictions = rf_model.transform(test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "rf_evaluator = MulticlassClassificationEvaluator(labelCol=\"cluster\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "rf_accuracy = rf_evaluator.evaluate(rf_predictions)\n",
    "print(f\"Accuracy of Random Forest Classifier: {rf_accuracy}\")\n",
    "print(\"Test Error for Random Forest Classifier = %g\" % (1.0 - rf_accuracy))\n",
    "# # Feature importances\n",
    "# importances = rf_model.featureImportances\n",
    "# print(f\"Feature Importances obtained by Random Forest Classifier: {importances}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "50cd5d2b-a0d2-4bc0-b860-0758a456fa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_trainingSummary = rf_model.summary\n",
    "rf_data = {\n",
    "    \"Label\": list(range(len(rf_trainingSummary.falsePositiveRateByLabel))),\n",
    "    \"False Positive Rate\": rf_trainingSummary.falsePositiveRateByLabel,\n",
    "    \"True Positive Rate\": rf_trainingSummary.truePositiveRateByLabel,\n",
    "    \"Precision\": rf_trainingSummary.precisionByLabel,\n",
    "    \"Recall\": rf_trainingSummary.recallByLabel,\n",
    "    \"F-Measure\": rf_trainingSummary.fMeasureByLabel(),\n",
    "}\n",
    "\n",
    "# Create a DataFrame for the per-label metrics\n",
    "rf_metrics_df = pd.DataFrame(rf_data)\n",
    "\n",
    "# Add overall metrics as a separate row\n",
    "overall_rf_metrics = pd.DataFrame([{\n",
    "    \"Label\": \"Overall\",\n",
    "    \"False Positive Rate\": rf_trainingSummary.weightedFalsePositiveRate,\n",
    "    \"True Positive Rate\": rf_trainingSummary.weightedTruePositiveRate,\n",
    "    \"Precision\": rf_trainingSummary.weightedPrecision,\n",
    "    \"Recall\": rf_trainingSummary.weightedRecall,\n",
    "    \"F-Measure\": rf_trainingSummary.weightedFMeasure(),\n",
    "}])\n",
    "\n",
    "# Combine the two DataFrames using pd.concat()\n",
    "rf_metrics_df = pd.concat([rf_metrics_df, overall_rf_metrics], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "47885688-6c47-482d-8ee8-2158be318f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>True Positive Rate</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F-Measure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.009053</td>\n",
       "      <td>0.992573</td>\n",
       "      <td>0.959440</td>\n",
       "      <td>0.992573</td>\n",
       "      <td>0.975725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.190905</td>\n",
       "      <td>0.997413</td>\n",
       "      <td>0.857294</td>\n",
       "      <td>0.997413</td>\n",
       "      <td>0.922061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.021240</td>\n",
       "      <td>0.608052</td>\n",
       "      <td>0.851575</td>\n",
       "      <td>0.608052</td>\n",
       "      <td>0.709499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.002361</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.971416</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.867295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Overall</td>\n",
       "      <td>0.107477</td>\n",
       "      <td>0.883917</td>\n",
       "      <td>0.861230</td>\n",
       "      <td>0.883917</td>\n",
       "      <td>0.865365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label  False Positive Rate  True Positive Rate  Precision    Recall  \\\n",
       "0        0             0.000000            0.000000   0.000000  0.000000   \n",
       "1        1             0.009053            0.992573   0.959440  0.992573   \n",
       "2        2             0.190905            0.997413   0.857294  0.997413   \n",
       "3        3             0.021240            0.608052   0.851575  0.608052   \n",
       "4        4             0.002361            0.783333   0.971416  0.783333   \n",
       "5  Overall             0.107477            0.883917   0.861230  0.883917   \n",
       "\n",
       "   F-Measure  \n",
       "0   0.000000  \n",
       "1   0.975725  \n",
       "2   0.922061  \n",
       "3   0.709499  \n",
       "4   0.867295  \n",
       "5   0.865365  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ed0f9f-b8bc-48be-92f8-5f29870efed3",
   "metadata": {},
   "source": [
    "DECISION TREE CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b19b6f4e-cb98-4ea4-9bc3-cfdab44d2e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.0944671 \n",
      "Accuracy of Decision Tree Classifer: 0.9055328513046211\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "dt = DecisionTreeClassifier(featuresCol='scaled_features', labelCol='cluster')\n",
    "dt_model = dt.fit(train_data)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "dt_predictions = dt_model.transform(test_data)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "dt_evaluator = MulticlassClassificationEvaluator(labelCol=\"cluster\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "dt_accuracy =dt_evaluator.evaluate(dt_predictions)\n",
    "print(\"Test Error = %g \" % (1.0 - dt_accuracy))\n",
    "print(f\"Accuracy of Decision Tree Classifer: {dt_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21fe45d-6376-4e90-81c7-88367f3607cd",
   "metadata": {},
   "source": [
    "NAIVE BAYES CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32f41ea5-86df-47bc-b0e6-55e17da1ed81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Naive Bayes Model: 0.9031751021691292\n"
     ]
    }
   ],
   "source": [
    "# Initialize Naive Bayes model\n",
    "naive_bayes = NaiveBayes(featuresCol=\"scaled_features\", labelCol=\"cluster\", modelType=\"multinomial\")\n",
    "\n",
    "# Train the Naive Bayes model\n",
    "nb_model = naive_bayes.fit(trainData)\n",
    "\n",
    "# Make predictions on test data\n",
    "nb_predictions = nb_model.transform(testData)\n",
    "\n",
    "# Evaluate the model using accuracy\n",
    "nb_evaluator = MulticlassClassificationEvaluator(labelCol=\"cluster\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "nb_accuracy = nb_evaluator.evaluate(nb_predictions)\n",
    "print(f\"Accuracy of Naive Bayes Model: {nb_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3837c069-88ef-4fcf-b633-85de08dab25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store the accuracies\n",
    "model_accuracy = []\n",
    "\n",
    "# Multinomial Logistic Regression\n",
    "model_accuracy.append((\"Multinomial Logistic Regression\", lr_accuracy))\n",
    "\n",
    "# Decision Tree\n",
    "model_accuracy.append((\"Decision Tree\", dt_accuracy))\n",
    "\n",
    "# Naive Bayes\n",
    "model_accuracy.append((\"Naive Bayes\", nb_accuracy))\n",
    "\n",
    "# Random Forest\n",
    "model_accuracy.append((\"Random Forest\", rf_accuracy))\n",
    "\n",
    "# Create a DataFrame from the list\n",
    "accuracy_df = pd.DataFrame(model_accuracy, columns=[\"model\", \"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e2a2ad88-76ec-43ba-9f35-0915b8badbe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multinomial Logistic Regression</td>\n",
       "      <td>0.972807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.905533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.903175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.887928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             model  accuracy\n",
       "0  Multinomial Logistic Regression  0.972807\n",
       "1                    Decision Tree  0.905533\n",
       "2                      Naive Bayes  0.903175\n",
       "3                    Random Forest  0.887928"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "738f2248-3a00-45ad-bf33-08909684c0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# For F1-Score\n",
    "f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"cluster\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "lr_f1_score = f1_evaluator.evaluate(lr_predictions)\n",
    "rf_f1_score = f1_evaluator.evaluate(rf_predictions)\n",
    "dt_f1_score = f1_evaluator.evaluate(dt_predictions)\n",
    "nb_f1_score = f1_evaluator.evaluate(nb_predictions)\n",
    "\n",
    "# For Precision\n",
    "precision_evaluator = MulticlassClassificationEvaluator(labelCol=\"cluster\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "lr_precision = precision_evaluator.evaluate(lr_predictions)\n",
    "rf_precision = precision_evaluator.evaluate(rf_predictions)\n",
    "dt_precision = precision_evaluator.evaluate(dt_predictions)\n",
    "nb_precision = precision_evaluator.evaluate(nb_predictions)\n",
    "\n",
    "# For Recall\n",
    "recall_evaluator = MulticlassClassificationEvaluator(labelCol=\"cluster\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "lr_recall = recall_evaluator.evaluate(lr_predictions)\n",
    "rf_recall = recall_evaluator.evaluate(rf_predictions)\n",
    "dt_recall = recall_evaluator.evaluate(dt_predictions)\n",
    "nb_recall = recall_evaluator.evaluate(nb_predictions)\n",
    "\n",
    "# Now you can store all these metrics in a list and build the DataFrame\n",
    "metrics = []\n",
    "\n",
    "# Assuming you have similar metrics for other models\n",
    "metrics.append((\"Multinomial Logistic Regression\", lr_accuracy, lr_f1_score, lr_precision, lr_recall))  # Replace with actual metrics\n",
    "metrics.append((\"Decision Tree\", dt_accuracy, dt_f1_score, dt_precision, dt_recall))\n",
    "metrics.append((\"Naive Bayes\", nb_accuracy, nb_f1_score, nb_precision, nb_recall))  # Replace with actual metrics\n",
    "metrics.append((\"Random Forest\", rf_accuracy, rf_f1_score, rf_precision, rf_recall))  # Replace with actual metrics\n",
    "\n",
    "\n",
    "# Create a DataFrame from the list\n",
    "metrics_df = pd.DataFrame(metrics, columns=[\"Model\", \"Accuracy\", \"F1_score\", \"Precision\", \"Recall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "05a8eb8d-c9d2-4818-8f1b-f37317ae6145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.905533</td>\n",
       "      <td>0.891291</td>\n",
       "      <td>0.906826</td>\n",
       "      <td>0.905533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Multinomial Logistic Regression</td>\n",
       "      <td>0.972807</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.972807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.903175</td>\n",
       "      <td>0.905019</td>\n",
       "      <td>0.910685</td>\n",
       "      <td>0.903175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.887928</td>\n",
       "      <td>0.870472</td>\n",
       "      <td>0.867024</td>\n",
       "      <td>0.887928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model  Accuracy  F1_score  Precision    Recall\n",
       "0                    Decision Tree  0.905533  0.891291   0.906826  0.905533\n",
       "1  Multinomial Logistic Regression  0.972807  0.972222   0.972222  0.972807\n",
       "2                      Naive Bayes  0.903175  0.905019   0.910685  0.903175\n",
       "3                    Random Forest  0.887928  0.870472   0.867024  0.887928"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e154453-503f-404a-a6c4-c94be0b1376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a parameter grid for hyperparameter tuning\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, [0.01, 0.1, 1.0])  # Regularization parameter\n",
    "             .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])  # ElasticNet mixing parameter\n",
    "             .addGrid(lr.maxIter, [10, 50, 100])  # Maximum number of iterations\n",
    "             .build())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "efaf33b5-aa13-4208-ae41-4f5d804dc5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up cross-validation\n",
    "cv = CrossValidator(estimator=lr, \n",
    "                    estimatorParamMaps=paramGrid, \n",
    "                    evaluator=lr_evaluator, \n",
    "                    numFolds=5)  # 5-fold cross-validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "85037261-2c91-4549-bf48-facd2ca37065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model using cross-validation\n",
    "cvModel = cv.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c99e26d2-9851-4ffe-b6f1-2aaabb5a5b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy =  0.9652624960704181\n",
      "Best Parameters:\n",
      "  MaxIter: 100\n",
      "  RegParam: 0.01\n",
      "  ElasticNetParam: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Get the best model from cross-validation\n",
    "bestModel = cvModel.bestModel\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = bestModel.transform(test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = lr_evaluator.evaluate(predictions)\n",
    "print(\"Test Accuracy = \", accuracy)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Parameters:\")\n",
    "print(\"  MaxIter:\", bestModel._java_obj.getMaxIter())\n",
    "print(\"  RegParam:\", bestModel._java_obj.getRegParam())\n",
    "print(\"  ElasticNetParam:\", bestModel._java_obj.getElasticNetParam())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b0303c-1d13-419f-94d6-e30b1fa2f60f",
   "metadata": {},
   "source": [
    "#### The result do not show any improvement in the accuracy instead there is slight decrease "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
