{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cd1070e-d031-4fcd-b38e-3adda1c39410",
   "metadata": {},
   "source": [
    "### IMPORTING PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17d189ba-6a97-49e6-8e8e-d7c287ebca59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql import DataFrame\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import (\n",
    "    min, max, year, month, col, isnan, isnull, when, count, countDistinct\n",
    ")\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.ml import Pipeline\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a195079-05bb-4340-8d0b-417103b3460f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\june3\\OneDrive\\Desktop\\my_output_result\n"
     ]
    }
   ],
   "source": [
    "# Changing the directory in the Colab notebook to a specific location within the Google Drive\n",
    "%cd C:\\Users\\june3\\OneDrive\\Desktop\\my_output_result\\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613dacd6-8e19-4b1f-a2af-401c8883bc99",
   "metadata": {},
   "source": [
    "### CREATE SPARK SESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ee6a7e3-266e-44f3-aae1-82196582fa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SDWA DATA ANALYSIS 1\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e9b997-9158-4e03-9483-df26ea750908",
   "metadata": {},
   "source": [
    "### LOADING .CSV FILES AND READING INTO SPARK DATAFRAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf5cab96-4f84-4752-8eeb-6af13f0eaf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Read all CSV files into a list of Spark DataFrames\n",
    "df = spark.read.csv(\"eda_analysis.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab7fcf4f-8410-45f3-b8a2-1cafbc9830a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_missing_values(df, dataframe_name):\n",
    "    # Compute missing values for each column\n",
    "    missing_df = df.select([\n",
    "        count(when(isnull(c) | isnan(c), c)).alias(c) for c in df.columns\n",
    "    ])\n",
    "    \n",
    "    # Convert to Pandas for better formatting\n",
    "    missing = missing_df.toPandas().transpose().reset_index()\n",
    "    missing.columns = ['Column', 'Missing_Count']\n",
    "    \n",
    "    # Display the missing values\n",
    "    print(f\"--- Missing Values in {dataframe_name} ---\")\n",
    "    print(missing.to_markdown(index=False))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53f82987-d67f-489f-b93f-b09e596715ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary_statistics(df, dataframe_name):\n",
    "    # Compute summary statistics\n",
    "    summary = df.describe().toPandas().set_index('summary').transpose()\n",
    "    \n",
    "    # Rename the index to the dataframe name for clarity\n",
    "    summary.index.name = 'Column'\n",
    "    \n",
    "    # Display the summary statistics\n",
    "    print(f\"--- Summary Statistics for {dataframe_name} ---\")\n",
    "    print(summary.to_markdown())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ad6131-4f00-423a-a02b-ccbd761f4fe4",
   "metadata": {},
   "source": [
    "### DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "703d71e6-9b78-4d85-b0fa-1cc43dbcad1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dataframe 1: rows: 43073, columns: 29 \n"
     ]
    }
   ],
   "source": [
    "print(f\" Dataframe : rows: {df.count()}, columns: {len(df.columns)} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7816e4d9-7521-4d48-b59d-5815c54ac7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars = [\"PWS_ACTIVITY_CODE\", \n",
    "            \"IS_SCHOOL_OR_DAYCARE_IND\",\n",
    "            \"SOURCE_WATER_PROTECTION_CODE\", \n",
    "            \"OUTSTANDING_PERFORMER\",\n",
    "            \"MANAGEMENT_OPS_EVAL_CODE\",\n",
    "            \"SOURCE_WATER_EVAL_CODE\",\n",
    "            \"SECURITY_EVAL_CODE\",\n",
    "            \"PUMPS_EVAL_CODE\",\n",
    "            \"OTHER_EVAL_CODE\",\n",
    "            \"COMPLIANCE_EVAL_CODE\",\n",
    "            \"DATA_VERIFICATION_EVAL_CODE\",\n",
    "            \"TREATMENT_EVAL_CODE\",\n",
    "            \"FINISHED_WATER_STOR_EVAL_CODE\",\n",
    "            \"DISTRIBUTION_EVAL_CODE\",\n",
    "            \"FINANCIAL_EVAL_CODE\",\n",
    "            \"VIOLATION_CATEGORY_CODE\",\n",
    "            \"IS_HEALTH_BASED_IND\",\n",
    "            \"IS_MAJOR_VIOL_IND\",\n",
    "            \"VIOLATION_STATUS\",\n",
    "            \"ENF_ACTION_CATEGORY\",\n",
    "           \"COMPLIANCE_STATUS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f34726b-4831-43da-99ca-083cbdbc3b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vars = [\"TOTAL_POPULATION_SERVED_COUNT_LOG\",\n",
    "            \"TOTAL_SERVICE_CONNECTIONS_COUNT_LOG\",\n",
    "            \"VIOL_MEASURE_LOG\",\n",
    "            \"TOTAL_VIOLATIONS_LOG\",\n",
    "            \"AVG_VIOLATION_DURATION_DAYS_LOG\",\n",
    "            \"OPEN_VIOLATIONS_COUNT_LOG\",\n",
    "            \"TOTAL_LATE_COMPLIANT_ACTIONS_LOG\"\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ca51686-6a35-47c8-88f5-f0a7e3af5e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Missing Values in DATAFRAME ---\n",
      "| Column                              |   Missing_Count |\n",
      "|:------------------------------------|----------------:|\n",
      "| PWSID                               |               0 |\n",
      "| PWS_ACTIVITY_CODE                   |               0 |\n",
      "| IS_SCHOOL_OR_DAYCARE_IND            |               0 |\n",
      "| SOURCE_WATER_PROTECTION_CODE        |               0 |\n",
      "| OUTSTANDING_PERFORMER               |               0 |\n",
      "| MANAGEMENT_OPS_EVAL_CODE            |               0 |\n",
      "| SOURCE_WATER_EVAL_CODE              |               0 |\n",
      "| SECURITY_EVAL_CODE                  |               0 |\n",
      "| PUMPS_EVAL_CODE                     |               0 |\n",
      "| OTHER_EVAL_CODE                     |               0 |\n",
      "| COMPLIANCE_EVAL_CODE                |               0 |\n",
      "| DATA_VERIFICATION_EVAL_CODE         |               0 |\n",
      "| TREATMENT_EVAL_CODE                 |               0 |\n",
      "| FINISHED_WATER_STOR_EVAL_CODE       |               0 |\n",
      "| DISTRIBUTION_EVAL_CODE              |               0 |\n",
      "| FINANCIAL_EVAL_CODE                 |               0 |\n",
      "| VIOLATION_CATEGORY_CODE             |               0 |\n",
      "| IS_HEALTH_BASED_IND                 |               0 |\n",
      "| IS_MAJOR_VIOL_IND                   |               0 |\n",
      "| VIOLATION_STATUS                    |               0 |\n",
      "| ENF_ACTION_CATEGORY                 |               0 |\n",
      "| COMPLIANCE_STATUS                   |               0 |\n",
      "| TOTAL_POPULATION_SERVED_COUNT_LOG   |               0 |\n",
      "| TOTAL_SERVICE_CONNECTIONS_COUNT_LOG |               0 |\n",
      "| VIOL_MEASURE_LOG                    |               0 |\n",
      "| TOTAL_VIOLATIONS_LOG                |               0 |\n",
      "| AVG_VIOLATION_DURATION_DAYS_LOG     |               0 |\n",
      "| OPEN_VIOLATIONS_COUNT_LOG           |               0 |\n",
      "| TOTAL_LATE_COMPLIANT_ACTIONS_LOG    |               0 |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_missing_values(df,  \"DATAFRAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44af62e1-0f60-4602-8e9a-df3368fd9a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline stages\n",
    "stages = []\n",
    "\n",
    "# Step 1: Process categorical variables\n",
    "for col in cat_vars:\n",
    "    # StringIndexer for categorical variable\n",
    "    indexer = StringIndexer(inputCol=col, outputCol=f\"{col}_indexed\")\n",
    "    stages.append(indexer)\n",
    "\n",
    "    # OneHotEncoder for indexed variable\n",
    "    encoder = OneHotEncoder(inputCol=f\"{col}_indexed\", outputCol=f\"{col}_encoded\")\n",
    "    stages.append(encoder)\n",
    "\n",
    "# Step 2: Combine all encoded categorical and numerical columns using VectorAssembler\n",
    "# Collect encoded categorical columns and add numerical columns\n",
    "assembled_input_cols = [f\"{col}_encoded\" for col in cat_vars] + num_vars\n",
    "\n",
    "assembler = VectorAssembler(inputCols=assembled_input_cols, outputCol=\"features\")\n",
    "stages.append(assembler)\n",
    "\n",
    "# Step 3: Create the pipeline\n",
    "pipeline = Pipeline(stages=stages)\n",
    "\n",
    "# Fit and transform the data\n",
    "final_df = pipeline.fit(df).transform(df)\n",
    "\n",
    "# final_df will have a \"features\" column with all categorical and numerical variables combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fab6b4df-4946-47d3-85b6-ca9fa13daf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PWSID: string (nullable = true)\n",
      " |-- PWS_ACTIVITY_CODE: string (nullable = true)\n",
      " |-- IS_SCHOOL_OR_DAYCARE_IND: string (nullable = true)\n",
      " |-- SOURCE_WATER_PROTECTION_CODE: string (nullable = true)\n",
      " |-- OUTSTANDING_PERFORMER: string (nullable = true)\n",
      " |-- MANAGEMENT_OPS_EVAL_CODE: string (nullable = true)\n",
      " |-- SOURCE_WATER_EVAL_CODE: string (nullable = true)\n",
      " |-- SECURITY_EVAL_CODE: string (nullable = true)\n",
      " |-- PUMPS_EVAL_CODE: string (nullable = true)\n",
      " |-- OTHER_EVAL_CODE: string (nullable = true)\n",
      " |-- COMPLIANCE_EVAL_CODE: string (nullable = true)\n",
      " |-- DATA_VERIFICATION_EVAL_CODE: string (nullable = true)\n",
      " |-- TREATMENT_EVAL_CODE: string (nullable = true)\n",
      " |-- FINISHED_WATER_STOR_EVAL_CODE: string (nullable = true)\n",
      " |-- DISTRIBUTION_EVAL_CODE: string (nullable = true)\n",
      " |-- FINANCIAL_EVAL_CODE: string (nullable = true)\n",
      " |-- VIOLATION_CATEGORY_CODE: string (nullable = true)\n",
      " |-- IS_HEALTH_BASED_IND: string (nullable = true)\n",
      " |-- IS_MAJOR_VIOL_IND: string (nullable = true)\n",
      " |-- VIOLATION_STATUS: string (nullable = true)\n",
      " |-- ENF_ACTION_CATEGORY: string (nullable = true)\n",
      " |-- COMPLIANCE_STATUS: string (nullable = true)\n",
      " |-- TOTAL_POPULATION_SERVED_COUNT_LOG: double (nullable = true)\n",
      " |-- TOTAL_SERVICE_CONNECTIONS_COUNT_LOG: double (nullable = true)\n",
      " |-- VIOL_MEASURE_LOG: double (nullable = true)\n",
      " |-- TOTAL_VIOLATIONS_LOG: double (nullable = true)\n",
      " |-- AVG_VIOLATION_DURATION_DAYS_LOG: double (nullable = true)\n",
      " |-- OPEN_VIOLATIONS_COUNT_LOG: double (nullable = true)\n",
      " |-- TOTAL_LATE_COMPLIANT_ACTIONS_LOG: double (nullable = true)\n",
      " |-- PWS_ACTIVITY_CODE_indexed: double (nullable = false)\n",
      " |-- PWS_ACTIVITY_CODE_encoded: vector (nullable = true)\n",
      " |-- IS_SCHOOL_OR_DAYCARE_IND_indexed: double (nullable = false)\n",
      " |-- IS_SCHOOL_OR_DAYCARE_IND_encoded: vector (nullable = true)\n",
      " |-- SOURCE_WATER_PROTECTION_CODE_indexed: double (nullable = false)\n",
      " |-- SOURCE_WATER_PROTECTION_CODE_encoded: vector (nullable = true)\n",
      " |-- OUTSTANDING_PERFORMER_indexed: double (nullable = false)\n",
      " |-- OUTSTANDING_PERFORMER_encoded: vector (nullable = true)\n",
      " |-- MANAGEMENT_OPS_EVAL_CODE_indexed: double (nullable = false)\n",
      " |-- MANAGEMENT_OPS_EVAL_CODE_encoded: vector (nullable = true)\n",
      " |-- SOURCE_WATER_EVAL_CODE_indexed: double (nullable = false)\n",
      " |-- SOURCE_WATER_EVAL_CODE_encoded: vector (nullable = true)\n",
      " |-- SECURITY_EVAL_CODE_indexed: double (nullable = false)\n",
      " |-- SECURITY_EVAL_CODE_encoded: vector (nullable = true)\n",
      " |-- PUMPS_EVAL_CODE_indexed: double (nullable = false)\n",
      " |-- PUMPS_EVAL_CODE_encoded: vector (nullable = true)\n",
      " |-- OTHER_EVAL_CODE_indexed: double (nullable = false)\n",
      " |-- OTHER_EVAL_CODE_encoded: vector (nullable = true)\n",
      " |-- COMPLIANCE_EVAL_CODE_indexed: double (nullable = false)\n",
      " |-- COMPLIANCE_EVAL_CODE_encoded: vector (nullable = true)\n",
      " |-- DATA_VERIFICATION_EVAL_CODE_indexed: double (nullable = false)\n",
      " |-- DATA_VERIFICATION_EVAL_CODE_encoded: vector (nullable = true)\n",
      " |-- TREATMENT_EVAL_CODE_indexed: double (nullable = false)\n",
      " |-- TREATMENT_EVAL_CODE_encoded: vector (nullable = true)\n",
      " |-- FINISHED_WATER_STOR_EVAL_CODE_indexed: double (nullable = false)\n",
      " |-- FINISHED_WATER_STOR_EVAL_CODE_encoded: vector (nullable = true)\n",
      " |-- DISTRIBUTION_EVAL_CODE_indexed: double (nullable = false)\n",
      " |-- DISTRIBUTION_EVAL_CODE_encoded: vector (nullable = true)\n",
      " |-- FINANCIAL_EVAL_CODE_indexed: double (nullable = false)\n",
      " |-- FINANCIAL_EVAL_CODE_encoded: vector (nullable = true)\n",
      " |-- VIOLATION_CATEGORY_CODE_indexed: double (nullable = false)\n",
      " |-- VIOLATION_CATEGORY_CODE_encoded: vector (nullable = true)\n",
      " |-- IS_HEALTH_BASED_IND_indexed: double (nullable = false)\n",
      " |-- IS_HEALTH_BASED_IND_encoded: vector (nullable = true)\n",
      " |-- IS_MAJOR_VIOL_IND_indexed: double (nullable = false)\n",
      " |-- IS_MAJOR_VIOL_IND_encoded: vector (nullable = true)\n",
      " |-- VIOLATION_STATUS_indexed: double (nullable = false)\n",
      " |-- VIOLATION_STATUS_encoded: vector (nullable = true)\n",
      " |-- ENF_ACTION_CATEGORY_indexed: double (nullable = false)\n",
      " |-- ENF_ACTION_CATEGORY_encoded: vector (nullable = true)\n",
      " |-- COMPLIANCE_STATUS_indexed: double (nullable = false)\n",
      " |-- COMPLIANCE_STATUS_encoded: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "209d9189-ac2b-46d3-87a2-dd4368b32fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the feature vector\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withMean=True, withStd=True)\n",
    "scaler_model = scaler.fit(final_df)\n",
    "scaled_data = scaler_model.transform(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80899160-0c3b-438d-be2f-a1efc594e778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[PWSID: string, PWS_ACTIVITY_CODE: string, IS_SCHOOL_OR_DAYCARE_IND: string, SOURCE_WATER_PROTECTION_CODE: string, OUTSTANDING_PERFORMER: string, MANAGEMENT_OPS_EVAL_CODE: string, SOURCE_WATER_EVAL_CODE: string, SECURITY_EVAL_CODE: string, PUMPS_EVAL_CODE: string, OTHER_EVAL_CODE: string, COMPLIANCE_EVAL_CODE: string, DATA_VERIFICATION_EVAL_CODE: string, TREATMENT_EVAL_CODE: string, FINISHED_WATER_STOR_EVAL_CODE: string, DISTRIBUTION_EVAL_CODE: string, FINANCIAL_EVAL_CODE: string, VIOLATION_CATEGORY_CODE: string, IS_HEALTH_BASED_IND: string, IS_MAJOR_VIOL_IND: string, VIOLATION_STATUS: string, ENF_ACTION_CATEGORY: string, COMPLIANCE_STATUS: string, TOTAL_POPULATION_SERVED_COUNT_LOG: double, TOTAL_SERVICE_CONNECTIONS_COUNT_LOG: double, VIOL_MEASURE_LOG: double, TOTAL_VIOLATIONS_LOG: double, AVG_VIOLATION_DURATION_DAYS_LOG: double, OPEN_VIOLATIONS_COUNT_LOG: double, TOTAL_LATE_COMPLIANT_ACTIONS_LOG: double, PWS_ACTIVITY_CODE_indexed: double, PWS_ACTIVITY_CODE_encoded: vector, IS_SCHOOL_OR_DAYCARE_IND_indexed: double, IS_SCHOOL_OR_DAYCARE_IND_encoded: vector, SOURCE_WATER_PROTECTION_CODE_indexed: double, SOURCE_WATER_PROTECTION_CODE_encoded: vector, OUTSTANDING_PERFORMER_indexed: double, OUTSTANDING_PERFORMER_encoded: vector, MANAGEMENT_OPS_EVAL_CODE_indexed: double, MANAGEMENT_OPS_EVAL_CODE_encoded: vector, SOURCE_WATER_EVAL_CODE_indexed: double, SOURCE_WATER_EVAL_CODE_encoded: vector, SECURITY_EVAL_CODE_indexed: double, SECURITY_EVAL_CODE_encoded: vector, PUMPS_EVAL_CODE_indexed: double, PUMPS_EVAL_CODE_encoded: vector, OTHER_EVAL_CODE_indexed: double, OTHER_EVAL_CODE_encoded: vector, COMPLIANCE_EVAL_CODE_indexed: double, COMPLIANCE_EVAL_CODE_encoded: vector, DATA_VERIFICATION_EVAL_CODE_indexed: double, DATA_VERIFICATION_EVAL_CODE_encoded: vector, TREATMENT_EVAL_CODE_indexed: double, TREATMENT_EVAL_CODE_encoded: vector, FINISHED_WATER_STOR_EVAL_CODE_indexed: double, FINISHED_WATER_STOR_EVAL_CODE_encoded: vector, DISTRIBUTION_EVAL_CODE_indexed: double, DISTRIBUTION_EVAL_CODE_encoded: vector, FINANCIAL_EVAL_CODE_indexed: double, FINANCIAL_EVAL_CODE_encoded: vector, VIOLATION_CATEGORY_CODE_indexed: double, VIOLATION_CATEGORY_CODE_encoded: vector, IS_HEALTH_BASED_IND_indexed: double, IS_HEALTH_BASED_IND_encoded: vector, IS_MAJOR_VIOL_IND_indexed: double, IS_MAJOR_VIOL_IND_encoded: vector, VIOLATION_STATUS_indexed: double, VIOLATION_STATUS_encoded: vector, ENF_ACTION_CATEGORY_indexed: double, ENF_ACTION_CATEGORY_encoded: vector, COMPLIANCE_STATUS_indexed: double, COMPLIANCE_STATUS_encoded: vector, features: vector, scaled_features: vector]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5a70654-1661-4c06-8d52-7113fef5ee88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract 'features' column from PySpark DataFrame and convert it to Pandas\n",
    "pandas_df = scaled_data.select('scaled_features').toPandas()\n",
    "\n",
    "# Convert the PySpark vector to a NumPy array that can be used in sklearn\n",
    "X = np.array(pandas_df['scaled_features'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f7dd359-6d03-4acf-87f9-81c6dd8415bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define range of number of clusters for Gaussian Mixture Model\n",
    "n_components_values = np.arange(2, 11, 1)  # Trying 2 to 10 clusters\n",
    "results = []\n",
    "\n",
    "for n_components in n_components_values:\n",
    "    # Initialize and fit GaussianMixture with the current number of components (clusters)\n",
    "    gmm = GaussianMixture(n_components=n_components)\n",
    "    labels = gmm.fit_predict(X)\n",
    "    \n",
    "    # Check if there are at least 2 clusters\n",
    "    unique_labels = set(labels)\n",
    "    num_clusters = len(unique_labels)\n",
    "    \n",
    "    if num_clusters > 1:\n",
    "        # Filter out noise points (if any, or just calculate metrics for valid clusters)\n",
    "        clustered_points = X\n",
    "        valid_labels = labels\n",
    "        \n",
    "        # Calculate metrics\n",
    "        silhouette = silhouette_score(clustered_points, valid_labels)\n",
    "        davies_bouldin = davies_bouldin_score(clustered_points, valid_labels)\n",
    "        calinski_harabasz = calinski_harabasz_score(clustered_points, valid_labels)\n",
    "        \n",
    "        # Store results\n",
    "        results.append([n_components, num_clusters, silhouette, davies_bouldin, calinski_harabasz])\n",
    "    else:\n",
    "        # Store results for the case where there are insufficient clusters\n",
    "        results.append([n_components, num_clusters, None, None, None])\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "df_results = pd.DataFrame(results, columns=[\"Number of Components\", \"Num Clusters\", \"Silhouette Score\", \"Davies-Bouldin Score\", \"Calinski-Harabasz Score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5d41503-7263-4ca3-a473-9479e99aaf37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Components</th>\n",
       "      <th>Num Clusters</th>\n",
       "      <th>Silhouette Score</th>\n",
       "      <th>Davies-Bouldin Score</th>\n",
       "      <th>Calinski-Harabasz Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.085948</td>\n",
       "      <td>3.359155</td>\n",
       "      <td>3218.931589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.121757</td>\n",
       "      <td>3.851437</td>\n",
       "      <td>3793.517552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.101578</td>\n",
       "      <td>4.053454</td>\n",
       "      <td>3086.613598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.212190</td>\n",
       "      <td>2.390156</td>\n",
       "      <td>3714.993102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.091839</td>\n",
       "      <td>3.369352</td>\n",
       "      <td>2510.114262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.086963</td>\n",
       "      <td>4.519894</td>\n",
       "      <td>1962.749526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.044361</td>\n",
       "      <td>3.779615</td>\n",
       "      <td>1865.821377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0.033040</td>\n",
       "      <td>3.753970</td>\n",
       "      <td>1756.404109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.071130</td>\n",
       "      <td>3.195556</td>\n",
       "      <td>2460.599126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of Components  Num Clusters  Silhouette Score  Davies-Bouldin Score  \\\n",
       "0                     2             2          0.085948              3.359155   \n",
       "1                     3             3          0.121757              3.851437   \n",
       "2                     4             4          0.101578              4.053454   \n",
       "3                     5             5          0.212190              2.390156   \n",
       "4                     6             6          0.091839              3.369352   \n",
       "5                     7             7          0.086963              4.519894   \n",
       "6                     8             8          0.044361              3.779615   \n",
       "7                     9             9          0.033040              3.753970   \n",
       "8                    10            10          0.071130              3.195556   \n",
       "\n",
       "   Calinski-Harabasz Score  \n",
       "0              3218.931589  \n",
       "1              3793.517552  \n",
       "2              3086.613598  \n",
       "3              3714.993102  \n",
       "4              2510.114262  \n",
       "5              1962.749526  \n",
       "6              1865.821377  \n",
       "7              1756.404109  \n",
       "8              2460.599126  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b17186c-a95c-4593-9a49-4966ddc47863",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = scaled_data.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d3423ebe-7492-4b4a-b3f2-341e45e43eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# Initialize and fit Gaussian Mixture Model\n",
    "n_components = 5\n",
    "gmm = GaussianMixture(n_components=n_components, random_state=0)\n",
    "gmm.fit(X)\n",
    "\n",
    "# Predict clusters\n",
    "labels = gmm.predict(X)\n",
    "df['cluster'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e2aa2103-01c8-401d-bcc8-20b39c03b95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIC: -11187231.194414672\n",
      "AIC: -11364259.888737725\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation\n",
    "# print(\"Means:\", gmm.means_)\n",
    "# print(\"Covariances:\", gmm.covariances_)\n",
    "print(\"BIC:\", gmm.bic(X))\n",
    "print(\"AIC:\", gmm.aic(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "09a090ae-9050-42e4-9492-64b45bbb4a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of data points in each cluster, including noise (-1)\n",
    "cluster_counts = pd.Series(labels).value_counts()\n",
    "\n",
    "# Calculate the percentage distribution of samples in each cluster\n",
    "percentage_distribution = (cluster_counts / len(labels)) * 100\n",
    "\n",
    "# Create a DataFrame with the counts and percentage distribution\n",
    "cluster_df = pd.DataFrame({\n",
    "    'Cluster': cluster_counts.index,\n",
    "    'Count': cluster_counts.values,\n",
    "    'Percentage': percentage_distribution.values\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "84b0625c-b22f-423c-97b5-512a4b92aa42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Cluster  Count  Percentage\n",
      "0        2  15535   36.066678\n",
      "1        3   7621   17.693218\n",
      "2        1   7427   17.242820\n",
      "3        5   7178   16.664732\n",
      "4        4   3638    8.446126\n",
      "5        0   1674    3.886425\n"
     ]
    }
   ],
   "source": [
    "print(cluster_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c81228fa-e940-488f-b541-db55f687f77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.13177563144775442\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Silhouette Score\n",
    "silhouette_avg = silhouette_score(X, labels)\n",
    "print(f'Silhouette Score: {silhouette_avg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bca73b10-8f65-4275-bb23-cf554a6eb081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin Index: 4.877368549128765\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Davies-Bouldin Index\n",
    "dbi = davies_bouldin_score(X, labels)\n",
    "print(f'Davies-Bouldin Index: {dbi}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e74ff79a-2287-4f42-9e8f-245fde7dd807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calinski-Harabasz Score: 2708.269285746137\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import calinski_harabasz_score\n",
    "# Calculate Calinski-Harabasz Score\n",
    "ch_score = calinski_harabasz_score(X, labels)\n",
    "print(\"Calinski-Harabasz Score:\", ch_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "05610bcb-2b78-49b0-a4f7-44501bb5bb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index=True if you want to save the DataFrame index\n",
    "df.to_csv('C:/Users/june3/OneDrive/Desktop/my_output_result/gmm_k5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df36885f-33ec-4f9e-939e-ba852e03baa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
