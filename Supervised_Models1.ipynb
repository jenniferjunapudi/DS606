{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86b3b4a2-ff5b-47ec-abcd-98c1121d1a72",
   "metadata": {},
   "source": [
    "IMPORTING PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1faf8a9-ca26-4d42-a098-857b2ebf90db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql import DataFrame\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import (\n",
    "    min, max, year, month, col, isnan, isnull, when, count, countDistinct, \n",
    "    round, desc, sum as sum_, mean, stddev, variance, skewness, kurtosis, \n",
    "    explode, split, regexp_replace, to_timestamp, to_date, lit, datediff, current_date\n",
    ")\n",
    "from pyspark.sql.types import StringType\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import create_map, lit\n",
    "from itertools import chain\n",
    "from pyspark.sql.functions import avg as F_avg\n",
    "from pyspark.sql.functions import sum as F_sum\n",
    "from pyspark.sql.functions import count as F_count\n",
    "from pyspark.sql.functions import col, round as F_round\n",
    "from pyspark.sql.functions import log1p \n",
    "import seaborn as sns\n",
    "from pyspark.ml.stat import Correlation\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "from pyspark.ml.linalg import Vectors\n",
    "import numpy as np\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler, MinMaxScaler\n",
    "from pyspark.ml.classification import LogisticRegression, OneVsRest\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import FMClassifier\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e350b529-6f94-413a-ad88-6c4a5c337f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\june3\\OneDrive\\Desktop\\my_output_result\n"
     ]
    }
   ],
   "source": [
    "# Changing the directory in the Colab notebook to a specific location within the Google Drive\n",
    "%cd C:\\Users\\june3\\OneDrive\\Desktop\\my_output_result\\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a639ca-949e-4410-88d5-f18cd4339ec7",
   "metadata": {},
   "source": [
    "CREATE SPARK SESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88f5cdb7-7e3b-4803-ac9c-d0e19c4e1d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SDWA DATA ANALYSIS 2\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f4109e3-5906-414c-9070-1f6af0fac2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Read all CSV files into a list of Spark DataFrames\n",
    "df = spark.read.csv(\"gmm_k5.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3a5b3dea-814d-4181-b48a-2cac08760a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_mapping = {0: 'High-Risk', \n",
    "                   1: 'Low-Risk', \n",
    "                   2: 'Moderate-Risk', \n",
    "                   3: 'Near-Compliant', \n",
    "                   4: 'Compliant'}\n",
    "\n",
    "mapping_expr = F.create_map([F.lit(x) for pair in cluster_mapping.items() for x in pair])\n",
    "df = df.withColumn('label', mapping_expr[df['cluster']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3367ed0e-3876-4882-a86c-954450c85375",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "025d33a4-83cf-4bc9-abf8-f70bd76e5d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index=True if you want to save the DataFrame index\n",
    "df.to_csv('C:/Users/june3/OneDrive/Desktop/my_output_result/cluster_label.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f384fb57-06b2-465d-b989-1c4c649e8491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PWSID: string (nullable = true)\n",
      " |-- PWS_ACTIVITY_CODE: string (nullable = true)\n",
      " |-- IS_SCHOOL_OR_DAYCARE_IND: string (nullable = true)\n",
      " |-- SOURCE_WATER_PROTECTION_CODE: string (nullable = true)\n",
      " |-- OUTSTANDING_PERFORMER: string (nullable = true)\n",
      " |-- MANAGEMENT_OPS_EVAL_CODE: string (nullable = true)\n",
      " |-- SOURCE_WATER_EVAL_CODE: string (nullable = true)\n",
      " |-- SECURITY_EVAL_CODE: string (nullable = true)\n",
      " |-- PUMPS_EVAL_CODE: string (nullable = true)\n",
      " |-- OTHER_EVAL_CODE: string (nullable = true)\n",
      " |-- COMPLIANCE_EVAL_CODE: string (nullable = true)\n",
      " |-- DATA_VERIFICATION_EVAL_CODE: string (nullable = true)\n",
      " |-- TREATMENT_EVAL_CODE: string (nullable = true)\n",
      " |-- FINISHED_WATER_STOR_EVAL_CODE: string (nullable = true)\n",
      " |-- DISTRIBUTION_EVAL_CODE: string (nullable = true)\n",
      " |-- FINANCIAL_EVAL_CODE: string (nullable = true)\n",
      " |-- VIOLATION_CATEGORY_CODE: string (nullable = true)\n",
      " |-- IS_HEALTH_BASED_IND: string (nullable = true)\n",
      " |-- IS_MAJOR_VIOL_IND: string (nullable = true)\n",
      " |-- VIOLATION_STATUS: string (nullable = true)\n",
      " |-- ENF_ACTION_CATEGORY: string (nullable = true)\n",
      " |-- COMPLIANCE_STATUS: string (nullable = true)\n",
      " |-- TOTAL_POPULATION_SERVED_COUNT_LOG: double (nullable = true)\n",
      " |-- TOTAL_SERVICE_CONNECTIONS_COUNT_LOG: double (nullable = true)\n",
      " |-- VIOL_MEASURE_LOG: double (nullable = true)\n",
      " |-- TOTAL_VIOLATIONS_LOG: double (nullable = true)\n",
      " |-- AVG_VIOLATION_DURATION_DAYS_LOG: double (nullable = true)\n",
      " |-- OPEN_VIOLATIONS_COUNT_LOG: double (nullable = true)\n",
      " |-- TOTAL_LATE_COMPLIANT_ACTIONS_LOG: double (nullable = true)\n",
      " |-- PWS_ACTIVITY_CODE_indexed: double (nullable = true)\n",
      " |-- PWS_ACTIVITY_CODE_encoded: string (nullable = true)\n",
      " |-- IS_SCHOOL_OR_DAYCARE_IND_indexed: double (nullable = true)\n",
      " |-- IS_SCHOOL_OR_DAYCARE_IND_encoded: string (nullable = true)\n",
      " |-- SOURCE_WATER_PROTECTION_CODE_indexed: double (nullable = true)\n",
      " |-- SOURCE_WATER_PROTECTION_CODE_encoded: string (nullable = true)\n",
      " |-- OUTSTANDING_PERFORMER_indexed: double (nullable = true)\n",
      " |-- OUTSTANDING_PERFORMER_encoded: string (nullable = true)\n",
      " |-- MANAGEMENT_OPS_EVAL_CODE_indexed: double (nullable = true)\n",
      " |-- MANAGEMENT_OPS_EVAL_CODE_encoded: string (nullable = true)\n",
      " |-- SOURCE_WATER_EVAL_CODE_indexed: double (nullable = true)\n",
      " |-- SOURCE_WATER_EVAL_CODE_encoded: string (nullable = true)\n",
      " |-- SECURITY_EVAL_CODE_indexed: double (nullable = true)\n",
      " |-- SECURITY_EVAL_CODE_encoded: string (nullable = true)\n",
      " |-- PUMPS_EVAL_CODE_indexed: double (nullable = true)\n",
      " |-- PUMPS_EVAL_CODE_encoded: string (nullable = true)\n",
      " |-- OTHER_EVAL_CODE_indexed: double (nullable = true)\n",
      " |-- OTHER_EVAL_CODE_encoded: string (nullable = true)\n",
      " |-- COMPLIANCE_EVAL_CODE_indexed: double (nullable = true)\n",
      " |-- COMPLIANCE_EVAL_CODE_encoded: string (nullable = true)\n",
      " |-- DATA_VERIFICATION_EVAL_CODE_indexed: double (nullable = true)\n",
      " |-- DATA_VERIFICATION_EVAL_CODE_encoded: string (nullable = true)\n",
      " |-- TREATMENT_EVAL_CODE_indexed: double (nullable = true)\n",
      " |-- TREATMENT_EVAL_CODE_encoded: string (nullable = true)\n",
      " |-- FINISHED_WATER_STOR_EVAL_CODE_indexed: double (nullable = true)\n",
      " |-- FINISHED_WATER_STOR_EVAL_CODE_encoded: string (nullable = true)\n",
      " |-- DISTRIBUTION_EVAL_CODE_indexed: double (nullable = true)\n",
      " |-- DISTRIBUTION_EVAL_CODE_encoded: string (nullable = true)\n",
      " |-- FINANCIAL_EVAL_CODE_indexed: double (nullable = true)\n",
      " |-- FINANCIAL_EVAL_CODE_encoded: string (nullable = true)\n",
      " |-- VIOLATION_CATEGORY_CODE_indexed: double (nullable = true)\n",
      " |-- VIOLATION_CATEGORY_CODE_encoded: string (nullable = true)\n",
      " |-- IS_HEALTH_BASED_IND_indexed: double (nullable = true)\n",
      " |-- IS_HEALTH_BASED_IND_encoded: string (nullable = true)\n",
      " |-- IS_MAJOR_VIOL_IND_indexed: double (nullable = true)\n",
      " |-- IS_MAJOR_VIOL_IND_encoded: string (nullable = true)\n",
      " |-- VIOLATION_STATUS_indexed: double (nullable = true)\n",
      " |-- VIOLATION_STATUS_encoded: string (nullable = true)\n",
      " |-- ENF_ACTION_CATEGORY_indexed: double (nullable = true)\n",
      " |-- ENF_ACTION_CATEGORY_encoded: string (nullable = true)\n",
      " |-- COMPLIANCE_STATUS_indexed: double (nullable = true)\n",
      " |-- COMPLIANCE_STATUS_encoded: string (nullable = true)\n",
      " |-- features: string (nullable = true)\n",
      " |-- scaled_features: string (nullable = true)\n",
      " |-- cluster: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1cf03d9-927b-473d-8e3d-1d2572c42f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select(\"PWSID\", \n",
    "            \"PWS_ACTIVITY_CODE\", \n",
    "            \"IS_SCHOOL_OR_DAYCARE_IND\",\n",
    "            \"SOURCE_WATER_PROTECTION_CODE\", \n",
    "            \"OUTSTANDING_PERFORMER\",\n",
    "            \"MANAGEMENT_OPS_EVAL_CODE\",\n",
    "            \"SOURCE_WATER_EVAL_CODE\",\n",
    "            \"SECURITY_EVAL_CODE\",\n",
    "            \"PUMPS_EVAL_CODE\",\n",
    "            \"OTHER_EVAL_CODE\",\n",
    "            \"COMPLIANCE_EVAL_CODE\",\n",
    "            \"DATA_VERIFICATION_EVAL_CODE\",\n",
    "            \"TREATMENT_EVAL_CODE\",\n",
    "            \"FINISHED_WATER_STOR_EVAL_CODE\",\n",
    "            \"DISTRIBUTION_EVAL_CODE\",\n",
    "            \"FINANCIAL_EVAL_CODE\",\n",
    "            \"VIOLATION_CATEGORY_CODE\",\n",
    "            \"IS_HEALTH_BASED_IND\",\n",
    "            \"IS_MAJOR_VIOL_IND\",\n",
    "            \"VIOLATION_STATUS\",\n",
    "            \"ENF_ACTION_CATEGORY\",\n",
    "           \"COMPLIANCE_STATUS\",\n",
    "            \"TOTAL_POPULATION_SERVED_COUNT_LOG\",\n",
    "            \"TOTAL_SERVICE_CONNECTIONS_COUNT_LOG\",\n",
    "            \"VIOL_MEASURE_LOG\",\n",
    "            \"TOTAL_VIOLATIONS_LOG\",\n",
    "            \"AVG_VIOLATION_DURATION_DAYS_LOG\",\n",
    "            \"OPEN_VIOLATIONS_COUNT_LOG\",\n",
    "            \"TOTAL_LATE_COMPLIANT_ACTIONS_LOG\",\n",
    "            \"cluster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84a9160b-2dea-41e7-a213-89ece426afb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PWSID: string (nullable = true)\n",
      " |-- PWS_ACTIVITY_CODE: string (nullable = true)\n",
      " |-- IS_SCHOOL_OR_DAYCARE_IND: string (nullable = true)\n",
      " |-- SOURCE_WATER_PROTECTION_CODE: string (nullable = true)\n",
      " |-- OUTSTANDING_PERFORMER: string (nullable = true)\n",
      " |-- MANAGEMENT_OPS_EVAL_CODE: string (nullable = true)\n",
      " |-- SOURCE_WATER_EVAL_CODE: string (nullable = true)\n",
      " |-- SECURITY_EVAL_CODE: string (nullable = true)\n",
      " |-- PUMPS_EVAL_CODE: string (nullable = true)\n",
      " |-- OTHER_EVAL_CODE: string (nullable = true)\n",
      " |-- COMPLIANCE_EVAL_CODE: string (nullable = true)\n",
      " |-- DATA_VERIFICATION_EVAL_CODE: string (nullable = true)\n",
      " |-- TREATMENT_EVAL_CODE: string (nullable = true)\n",
      " |-- FINISHED_WATER_STOR_EVAL_CODE: string (nullable = true)\n",
      " |-- DISTRIBUTION_EVAL_CODE: string (nullable = true)\n",
      " |-- FINANCIAL_EVAL_CODE: string (nullable = true)\n",
      " |-- VIOLATION_CATEGORY_CODE: string (nullable = true)\n",
      " |-- IS_HEALTH_BASED_IND: string (nullable = true)\n",
      " |-- IS_MAJOR_VIOL_IND: string (nullable = true)\n",
      " |-- VIOLATION_STATUS: string (nullable = true)\n",
      " |-- ENF_ACTION_CATEGORY: string (nullable = true)\n",
      " |-- COMPLIANCE_STATUS: string (nullable = true)\n",
      " |-- TOTAL_POPULATION_SERVED_COUNT_LOG: double (nullable = true)\n",
      " |-- TOTAL_SERVICE_CONNECTIONS_COUNT_LOG: double (nullable = true)\n",
      " |-- VIOL_MEASURE_LOG: double (nullable = true)\n",
      " |-- TOTAL_VIOLATIONS_LOG: double (nullable = true)\n",
      " |-- AVG_VIOLATION_DURATION_DAYS_LOG: double (nullable = true)\n",
      " |-- OPEN_VIOLATIONS_COUNT_LOG: double (nullable = true)\n",
      " |-- TOTAL_LATE_COMPLIANT_ACTIONS_LOG: double (nullable = true)\n",
      " |-- cluster: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a2b034a-1e48-4040-9688-c3d9a8826e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_missing_values(df, dataframe_name):\n",
    "    # Compute missing values for each column\n",
    "    missing_df = df.select([\n",
    "        count(when(isnull(c) | isnan(c), c)).alias(c) for c in df.columns\n",
    "    ])\n",
    "    \n",
    "    # Convert to Pandas for better formatting\n",
    "    missing = missing_df.toPandas().transpose().reset_index()\n",
    "    missing.columns = ['Column', 'Missing_Count']\n",
    "    \n",
    "    # Display the missing values\n",
    "    print(f\"--- Missing Values in {dataframe_name} ---\")\n",
    "    print(missing.to_markdown(index=False))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42b53409-c011-45fa-8e8c-76632522b87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary_statistics(df, dataframe_name):\n",
    "    # Compute summary statistics\n",
    "    summary = df.describe().toPandas().set_index('summary').transpose()\n",
    "    \n",
    "    # Rename the index to the dataframe name for clarity\n",
    "    summary.index.name = 'Column'\n",
    "    \n",
    "    # Display the summary statistics\n",
    "    print(f\"--- Summary Statistics for {dataframe_name} ---\")\n",
    "    print(summary.to_markdown())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519135dd-f21b-4e1b-a8ec-7a9ffb66b8e5",
   "metadata": {},
   "source": [
    "DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a107fe9f-621f-405a-b7a5-07ae825fc6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dataframe 1: rows: 43073, columns: 30 \n"
     ]
    }
   ],
   "source": [
    "print(f\" Dataframe 1: rows: {df.count()}, columns: {len(df.columns)} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b998f003-d9a7-4fd9-bacf-cee56c7a2f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars = [\"PWS_ACTIVITY_CODE\", \n",
    "            \"IS_SCHOOL_OR_DAYCARE_IND\",\n",
    "            \"SOURCE_WATER_PROTECTION_CODE\", \n",
    "            \"OUTSTANDING_PERFORMER\",\n",
    "            \"MANAGEMENT_OPS_EVAL_CODE\",\n",
    "            \"SOURCE_WATER_EVAL_CODE\",\n",
    "            \"SECURITY_EVAL_CODE\",\n",
    "            \"PUMPS_EVAL_CODE\",\n",
    "            \"OTHER_EVAL_CODE\",\n",
    "            \"COMPLIANCE_EVAL_CODE\",\n",
    "            \"DATA_VERIFICATION_EVAL_CODE\",\n",
    "            \"TREATMENT_EVAL_CODE\",\n",
    "            \"FINISHED_WATER_STOR_EVAL_CODE\",\n",
    "            \"DISTRIBUTION_EVAL_CODE\",\n",
    "            \"FINANCIAL_EVAL_CODE\",\n",
    "            \"VIOLATION_CATEGORY_CODE\",\n",
    "            \"IS_HEALTH_BASED_IND\",\n",
    "            \"IS_MAJOR_VIOL_IND\",\n",
    "            \"VIOLATION_STATUS\",\n",
    "            \"ENF_ACTION_CATEGORY\",\n",
    "           \"COMPLIANCE_STATUS\",\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6011115c-f95d-49f8-817b-bb5b8404a3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vars = [\"TOTAL_POPULATION_SERVED_COUNT_LOG\",\n",
    "            \"TOTAL_SERVICE_CONNECTIONS_COUNT_LOG\",\n",
    "            \"VIOL_MEASURE_LOG\",\n",
    "            \"TOTAL_VIOLATIONS_LOG\",\n",
    "            \"AVG_VIOLATION_DURATION_DAYS_LOG\",\n",
    "            \"OPEN_VIOLATIONS_COUNT_LOG\",\n",
    "            \"TOTAL_LATE_COMPLIANT_ACTIONS_LOG\",\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a42be759-232f-41e1-91af-31482473fc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline stages\n",
    "stages = []\n",
    "\n",
    "# Step 1: Process categorical variables\n",
    "for col in cat_vars:\n",
    "    # StringIndexer for categorical variable\n",
    "    indexer = StringIndexer(inputCol=col, outputCol=f\"{col}_indexed\")\n",
    "    stages.append(indexer)\n",
    "\n",
    "    # OneHotEncoder for indexed variable\n",
    "    encoder = OneHotEncoder(inputCol=f\"{col}_indexed\", outputCol=f\"{col}_encoded\")\n",
    "    stages.append(encoder)\n",
    "\n",
    "# Step 2: Combine all encoded categorical and numerical columns using VectorAssembler\n",
    "# Collect encoded categorical columns and add numerical columns\n",
    "assembled_input_cols = [f\"{col}_encoded\" for col in cat_vars] + num_vars\n",
    "\n",
    "assembler = VectorAssembler(inputCols=assembled_input_cols, outputCol=\"features\")\n",
    "stages.append(assembler)\n",
    "\n",
    "# Step 3: Create the pipeline\n",
    "pipeline = Pipeline(stages=stages)\n",
    "\n",
    "# Fit and transform the data\n",
    "final_df = pipeline.fit(df).transform(df)\n",
    "\n",
    "# final_df will have a \"features\" column with all categorical and numerical variables combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7830a39b-ca39-401a-a605-3066f184b4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the feature vector\n",
    "scaler1 = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withMean=True, withStd=True)\n",
    "scaler_model1 = scaler1.fit(final_df)\n",
    "scaled_data1 = scaler_model1.transform(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c006acdd-3fe6-4cc8-8e32-1bef51af592c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler2 = MinMaxScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n",
    "scaler_model2 = scaler2.fit(final_df)\n",
    "scaled_data2 = scaler_model2.transform(final_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e89364ac-a1b1-4325-aa8d-4ef27a31b383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract 'features' column from PySpark DataFrame and convert it to Pandas\n",
    "# pandas_df = scaled_data.select('scaled_features').toPandas()\n",
    "\n",
    "# # Convert the PySpark vector to a NumPy array that can be used in sklearn\n",
    "# X = np.array(pandas_df['scaled_features'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e768044-247c-4f53-80f7-9bd141b5c857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets (70% training, 30% testing)\n",
    "train_data, test_data = scaled_data1.randomSplit([0.7, 0.3], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36c03e09-6649-4cbc-bbce-207450685a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData, testData = scaled_data2.randomSplit([0.7, 0.3], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80f75e9-6b19-42ce-ab30-f779f69add64",
   "metadata": {},
   "source": [
    "MULTINOMIAL LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc74a59c-38a4-4c8e-afec-ce880bdd3ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Multinomial Logistic Regression Model: 0.9728072933039924\n",
      "F1-Score of Multinomial Logistic Regression Model: 0.9722223615356852\n"
     ]
    }
   ],
   "source": [
    "# Initialize Multinomial Logistic Regression model\n",
    "lr = LogisticRegression(featuresCol=\"scaled_features\", labelCol=\"cluster\", family=\"multinomial\", maxIter=10)\n",
    "\n",
    "# Train the Multinomial Logistic Regression model\n",
    "lr_model = lr.fit(train_data)\n",
    "\n",
    "# Make predictions on test data\n",
    "lr_predictions = lr_model.transform(test_data)\n",
    "\n",
    "# Evaluate the model using accuracy\n",
    "lr_evaluator = MulticlassClassificationEvaluator(labelCol=\"cluster\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "lr_accuracy = lr_evaluator.evaluate(lr_predictions)\n",
    "print(f\"Accuracy of Multinomial Logistic Regression Model: {lr_accuracy}\")\n",
    "\n",
    "# You can also evaluate using other metrics, such as F1-Score or AUC (if applicable)\n",
    "f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"cluster\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1_score = f1_evaluator.evaluate(lr_predictions)\n",
    "print(f\"F1-Score of Multinomial Logistic Regression Model: {f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "40ef0f26-2218-455b-b833-64c0fe5d9bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary to hold the metrics\n",
    "metrics_dict = {}\n",
    "\n",
    "\n",
    "trainingSummary = lr_model.summary\n",
    "\n",
    "\n",
    "# False Positive Rate (FPR) by label\n",
    "fpr_by_label = [rate for rate in trainingSummary.falsePositiveRateByLabel]\n",
    "metrics_dict[\"false_positive_rate_by_label\"] = fpr_by_label\n",
    "\n",
    "# True Positive Rate (TPR) by label\n",
    "tpr_by_label = [rate for rate in trainingSummary.truePositiveRateByLabel]\n",
    "metrics_dict[\"true_positive_rate_by_label\"] = tpr_by_label\n",
    "\n",
    "# Precision by label\n",
    "precision_by_label = [prec for prec in trainingSummary.precisionByLabel]\n",
    "metrics_dict[\"precision_by_label\"] = precision_by_label\n",
    "\n",
    "# Recall by label\n",
    "recall_by_label = [rec for rec in trainingSummary.recallByLabel]\n",
    "metrics_dict[\"recall_by_label\"] = recall_by_label\n",
    "\n",
    "# F-measure by label\n",
    "f_measure_by_label = [f for f in trainingSummary.fMeasureByLabel()]\n",
    "metrics_dict[\"f_measure_by_label\"] = f_measure_by_label\n",
    "\n",
    "# Overall Metrics\n",
    "metrics_dict[\"accuracy\"] = trainingSummary.accuracy\n",
    "metrics_dict[\"weighted_false_positive_rate\"] = trainingSummary.weightedFalsePositiveRate\n",
    "metrics_dict[\"weighted_true_positive_rate\"] = trainingSummary.weightedTruePositiveRate\n",
    "metrics_dict[\"weighted_f_measure\"] = trainingSummary.weightedFMeasure()\n",
    "metrics_dict[\"weighted_precision\"] = trainingSummary.weightedPrecision\n",
    "metrics_dict[\"weighted_recall\"] = trainingSummary.weightedRecall\n",
    "\n",
    "# Convert the dictionary to a pandas DataFrame\n",
    "metrics_df = pd.DataFrame([metrics_dict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "023dea03-dab9-43db-924b-e1b382c8ade8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>false_positive_rate_by_label</th>\n",
       "      <th>true_positive_rate_by_label</th>\n",
       "      <th>precision_by_label</th>\n",
       "      <th>recall_by_label</th>\n",
       "      <th>f_measure_by_label</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>weighted_false_positive_rate</th>\n",
       "      <th>weighted_true_positive_rate</th>\n",
       "      <th>weighted_f_measure</th>\n",
       "      <th>weighted_precision</th>\n",
       "      <th>weighted_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.001559057786815794, 0.005448063133437487, 0...</td>\n",
       "      <td>[0.7535545023696683, 0.9860750092833271, 0.999...</td>\n",
       "      <td>[0.9325513196480938, 0.9750321277767579, 0.982...</td>\n",
       "      <td>[0.7535545023696683, 0.9860750092833271, 0.999...</td>\n",
       "      <td>[0.8335517693315858, 0.9805224776146958, 0.990...</td>\n",
       "      <td>0.972849</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.972849</td>\n",
       "      <td>0.972234</td>\n",
       "      <td>0.972391</td>\n",
       "      <td>0.972849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        false_positive_rate_by_label  \\\n",
       "0  [0.001559057786815794, 0.005448063133437487, 0...   \n",
       "\n",
       "                         true_positive_rate_by_label  \\\n",
       "0  [0.7535545023696683, 0.9860750092833271, 0.999...   \n",
       "\n",
       "                                  precision_by_label  \\\n",
       "0  [0.9325513196480938, 0.9750321277767579, 0.982...   \n",
       "\n",
       "                                     recall_by_label  \\\n",
       "0  [0.7535545023696683, 0.9860750092833271, 0.999...   \n",
       "\n",
       "                                  f_measure_by_label  accuracy  \\\n",
       "0  [0.8335517693315858, 0.9805224776146958, 0.990...  0.972849   \n",
       "\n",
       "   weighted_false_positive_rate  weighted_true_positive_rate  \\\n",
       "0                      0.014064                     0.972849   \n",
       "\n",
       "   weighted_f_measure  weighted_precision  weighted_recall  \n",
       "0            0.972234            0.972391         0.972849  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d149a44a-1119-417b-9693-18452143b432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objectiveHistory:\n",
      "1.2607909003227766\n",
      "0.5001694740841492\n",
      "0.4514971615696827\n",
      "0.31319607814292844\n",
      "0.25267344481613324\n",
      "0.20535604539735605\n",
      "0.18063481920463284\n",
      "0.1594381227542598\n",
      "0.1343653077898365\n",
      "0.10887408972637413\n",
      "0.09793206662087564\n",
      "False positive rate by label:\n",
      "label 0: 0.001559057786815794\n",
      "label 1: 0.005448063133437487\n",
      "label 2: 0.020755117942905715\n",
      "label 3: 0.009492919863934815\n",
      "label 4: 0.003959460932107959\n",
      "True positive rate by label:\n",
      "label 0: 0.7535545023696683\n",
      "label 1: 0.9860750092833271\n",
      "label 2: 0.9998151798915722\n",
      "label 3: 0.9102032761002565\n",
      "label 4: 0.9705673758865249\n",
      "Precision by label:\n",
      "label 0: 0.9325513196480938\n",
      "label 1: 0.9750321277767579\n",
      "label 2: 0.9822660694831135\n",
      "label 3: 0.9505358615004122\n",
      "label 4: 0.9617006324666199\n",
      "Recall by label:\n",
      "label 0: 0.7535545023696683\n",
      "label 1: 0.9860750092833271\n",
      "label 2: 0.9998151798915722\n",
      "label 3: 0.9102032761002565\n",
      "label 4: 0.9705673758865249\n",
      "F-measure by label:\n",
      "label 0: 0.8335517693315858\n",
      "label 1: 0.9805224776146958\n",
      "label 2: 0.990962935824632\n",
      "label 3: 0.9299324528682327\n",
      "label 4: 0.966113660430639\n",
      "Accuracy: 0.9728491877821345\n",
      "FPR: 0.014063807441336274\n",
      "TPR: 0.9728491877821345\n",
      "F-measure: 0.9722340239596619\n",
      "Precision: 0.9723911887580139\n",
      "Recall: 0.9728491877821345\n"
     ]
    }
   ],
   "source": [
    "# Obtain the objective per iteration\n",
    "objectiveHistory = trainingSummary.objectiveHistory\n",
    "print(\"objectiveHistory:\")\n",
    "for objective in objectiveHistory:\n",
    "    print(objective)\n",
    "\n",
    "# for multiclass, we can inspect metrics on a per-label basis\n",
    "print(\"False positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.falsePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "print(\"True positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.truePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "print(\"Precision by label:\")\n",
    "for i, prec in enumerate(trainingSummary.precisionByLabel):\n",
    "    print(\"label %d: %s\" % (i, prec))\n",
    "\n",
    "print(\"Recall by label:\")\n",
    "for i, rec in enumerate(trainingSummary.recallByLabel):\n",
    "    print(\"label %d: %s\" % (i, rec))\n",
    "\n",
    "print(\"F-measure by label:\")\n",
    "for i, f in enumerate(trainingSummary.fMeasureByLabel()):\n",
    "    print(\"label %d: %s\" % (i, f))\n",
    "\n",
    "accuracy = trainingSummary.accuracy\n",
    "falsePositiveRate = trainingSummary.weightedFalsePositiveRate\n",
    "truePositiveRate = trainingSummary.weightedTruePositiveRate\n",
    "fMeasure = trainingSummary.weightedFMeasure()\n",
    "precision = trainingSummary.weightedPrecision\n",
    "recall = trainingSummary.weightedRecall\n",
    "print(\"Accuracy: %s\\nFPR: %s\\nTPR: %s\\nF-measure: %s\\nPrecision: %s\\nRecall: %s\"\n",
    "      % (accuracy, falsePositiveRate, truePositiveRate, fMeasure, precision, recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d382fbfa-19e0-415c-821b-2e3c23eedc29",
   "metadata": {},
   "source": [
    "RANDOM FOREST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "feade112-e84a-492f-8d1c-56fccdf2df5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest Classifier: 0.8847846589122917\n",
      "Test Error for Random Forest Classifier = 0.115215\n"
     ]
    }
   ],
   "source": [
    "# Initialize the RandomForestClassifier\n",
    "rf = RandomForestClassifier(labelCol=\"cluster\", featuresCol=\"scaled_features\", numTrees=100)\n",
    "\n",
    "# Train the model\n",
    "rf_model = rf.fit(train_data)\n",
    "\n",
    "# Make predictions on the test set\n",
    "rf_predictions = rf_model.transform(test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "rf_evaluator = MulticlassClassificationEvaluator(labelCol=\"cluster\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "rf_accuracy = rf_evaluator.evaluate(rf_predictions)\n",
    "print(f\"Accuracy of Random Forest Classifier: {rf_accuracy}\")\n",
    "print(\"Test Error for Random Forest Classifier = %g\" % (1.0 - rf_accuracy))\n",
    "# # Feature importances\n",
    "# importances = rf_model.featureImportances\n",
    "# print(f\"Feature Importances obtained by Random Forest Classifier: {importances}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8fb12bf8-8c56-403e-830f-9b2dfb858408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainingSummary = rf_model.summary\n",
    "\n",
    "# # for multiclass, we can inspect metrics on a per-label basis\n",
    "# print(\"False positive rate by label:\")\n",
    "# for i, rate in enumerate(trainingSummary.falsePositiveRateByLabel):\n",
    "#     print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "# print(\"True positive rate by label:\")\n",
    "# for i, rate in enumerate(trainingSummary.truePositiveRateByLabel):\n",
    "#     print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "# print(\"Precision by label:\")\n",
    "# for i, prec in enumerate(trainingSummary.precisionByLabel):\n",
    "#     print(\"label %d: %s\" % (i, prec))\n",
    "\n",
    "# print(\"Recall by label:\")\n",
    "# for i, rec in enumerate(trainingSummary.recallByLabel):\n",
    "#     print(\"label %d: %s\" % (i, rec))\n",
    "\n",
    "# print(\"F-measure by label:\")\n",
    "# for i, f in enumerate(trainingSummary.fMeasureByLabel()):\n",
    "#     print(\"label %d: %s\" % (i, f))\n",
    "\n",
    "# accuracy = trainingSummary.accuracy\n",
    "# falsePositiveRate = trainingSummary.weightedFalsePositiveRate\n",
    "# truePositiveRate = trainingSummary.weightedTruePositiveRate\n",
    "# fMeasure = trainingSummary.weightedFMeasure()\n",
    "# precision = trainingSummary.weightedPrecision\n",
    "# recall = trainingSummary.weightedRecall\n",
    "# print(\"Accuracy: %s\\nFPR: %s\\nTPR: %s\\nF-measure: %s\\nPrecision: %s\\nRecall: %s\"\n",
    "#       % (accuracy, falsePositiveRate, truePositiveRate, fMeasure, precision, recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ed0f9f-b8bc-48be-92f8-5f29870efed3",
   "metadata": {},
   "source": [
    "DECISION TREE CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b19b6f4e-cb98-4ea4-9bc3-cfdab44d2e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.0944671 \n",
      "Accuracy of Decision Tree Classifer: 0.9055328513046211\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "dt = DecisionTreeClassifier(featuresCol='scaled_features', labelCol='cluster')\n",
    "dt_model = dt.fit(train_data)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "dt_predictions = dt_model.transform(test_data)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "dt_evaluator = MulticlassClassificationEvaluator(labelCol=\"cluster\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "dt_accuracy =dt_evaluator.evaluate(dt_predictions)\n",
    "print(\"Test Error = %g \" % (1.0 - dt_accuracy))\n",
    "print(f\"Accuracy of Decision Tree Classifer: {dt_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21fe45d-6376-4e90-81c7-88367f3607cd",
   "metadata": {},
   "source": [
    "NAIVE BAYES CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "32f41ea5-86df-47bc-b0e6-55e17da1ed81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Naive Bayes Model: 0.9031751021691292\n"
     ]
    }
   ],
   "source": [
    "# Initialize Naive Bayes model\n",
    "naive_bayes = NaiveBayes(featuresCol=\"scaled_features\", labelCol=\"cluster\", modelType=\"multinomial\")\n",
    "\n",
    "# Train the Naive Bayes model\n",
    "nb_model = naive_bayes.fit(trainData)\n",
    "\n",
    "# Make predictions on test data\n",
    "nb_predictions = nb_model.transform(testData)\n",
    "\n",
    "# Evaluate the model using accuracy\n",
    "nb_evaluator = MulticlassClassificationEvaluator(labelCol=\"cluster\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "nb_accuracy = nb_evaluator.evaluate(nb_predictions)\n",
    "print(f\"Accuracy of Naive Bayes Model: {nb_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e154453-503f-404a-a6c4-c94be0b1376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "\n",
    "# Build a parameter grid for hyperparameter tuning\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, [0.01, 0.1, 1.0])  # Regularization parameter\n",
    "             .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])  # ElasticNet mixing parameter\n",
    "             .addGrid(lr.maxIter, [10, 50, 100])  # Maximum number of iterations\n",
    "             .build())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "efaf33b5-aa13-4208-ae41-4f5d804dc5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator\n",
    "\n",
    "# Set up cross-validation\n",
    "cv = CrossValidator(estimator=lr, \n",
    "                    estimatorParamMaps=paramGrid, \n",
    "                    evaluator=lr_evaluator, \n",
    "                    numFolds=5)  # 5-fold cross-validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2320af-2ed6-46cd-88f8-d51836e5a5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.ml.tuning import TrainValidationSplit\n",
    "\n",
    "# # Set up train-validation split\n",
    "# tvs = TrainValidationSplit(estimator=lr,\n",
    "#                            estimatorParamMaps=paramGrid,\n",
    "#                            evaluator=lr_evaluator,\n",
    "#                            trainRatio=0.8)  # 80% for training, 20% for validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "85037261-2c91-4549-bf48-facd2ca37065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model using cross-validation\n",
    "cvModel = cv.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14238ae-c2ff-4de3-8305-b64db128b759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Or using train-validation split\n",
    "# tvsModel = tvs.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c99e26d2-9851-4ffe-b6f1-2aaabb5a5b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy =  0.9652624960704181\n",
      "Best Parameters:\n",
      "  MaxIter: 100\n",
      "  RegParam: 0.01\n",
      "  ElasticNetParam: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Get the best model from cross-validation\n",
    "bestModel = cvModel.bestModel\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = bestModel.transform(test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = lr_evaluator.evaluate(predictions)\n",
    "print(\"Test Accuracy = \", accuracy)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Parameters:\")\n",
    "print(\"  MaxIter:\", bestModel._java_obj.getMaxIter())\n",
    "print(\"  RegParam:\", bestModel._java_obj.getRegParam())\n",
    "print(\"  ElasticNetParam:\", bestModel._java_obj.getElasticNetParam())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656075e3-ab54-4a7c-b4fd-e6bb48f8781b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestModel.save(\"path_to_save_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6141b7a2-340e-4be8-8cfc-a10eed00b4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define KNN classifier\n",
    "# knn = KNNClassifier(k=5, featuresCol=\"scaledFeatures\", labelCol=\"label\", predictionCol=\"prediction\")\n",
    "# knn_model = knn.fit(train_data)\n",
    "\n",
    "# # Predict on test data\n",
    "# predictions = knn_model.transform(test_data)\n",
    "# predictions.select(\"label\", \"prediction\").show()\n",
    "\n",
    "# evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "# accuracy = evaluator.evaluate(predictions)\n",
    "# print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d555034-bc96-4b4d-a0d6-1060ef17e9d4",
   "metadata": {},
   "source": [
    "LINEAR SUPPORT VECTOR MACHINE CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d069483-8e7e-443b-a4f5-49414a716a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize Linear SVC\n",
    "# svm = LinearSVC(featuresCol=\"scaled_features\", labelCol=\"cluster\", maxIter=10, regParam=0.1)\n",
    "\n",
    "# # Train the model\n",
    "# svm_model = svm.fit(train_data)\n",
    "\n",
    "# # Predict on test data\n",
    "# svm_predictions = svm_model.transform(test_data)\n",
    "# svm_predictions.select(\"cluster\", \"prediction\").show(5)\n",
    "\n",
    "# # Initialize evaluator\n",
    "# svm_evaluator = MulticlassClassificationEvaluator(labelCol=\"cluster\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "# # Calculate accuracy\n",
    "# svm_accuracy = svm_evaluator.evaluate(predictions)\n",
    "\n",
    "# print(\"Test Error = %g \" % (1.0 - svm_accuracy))\n",
    "# print(f\"Accuracy of Support Vector Machine Model: {svm_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e88977e-1433-451a-a46c-f2aeca647934",
   "metadata": {},
   "source": [
    "GRADIENT-BOOSTED TREE CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e28b855-c459-4fcf-8540-b85d228c3b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize Gradient Boosting Classifier\n",
    "# gbt = GBTClassifier(featuresCol=\"scaled_features\", labelCol=\"cluster\", maxIter=10)\n",
    "\n",
    "# # Train the model\n",
    "# gbt_model = gbt.fit(train_data)\n",
    "\n",
    "# # Make predictions on test data\n",
    "# gbt_predictions = gbt_model.transform(test_data)\n",
    "\n",
    "# # Evaluate the model using accuracy\n",
    "# gbt_evaluator = MulticlassClassificationEvaluator(labelCol=\"cluster\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "# gbt_accuracy = gbt_evaluator.evaluate(gbt_predictions)\n",
    "# print(f\"Accuracy of Gradient Boosting Model: {gbt_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b342623c-302a-490d-83e7-a1a7162f16f1",
   "metadata": {},
   "source": [
    "Gradient Boosted Trees require sufficient samples for each class. If the dataset is heavily imbalanced, the model may fail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3599e189-4b6a-4030-a71e-5ef8b3592182",
   "metadata": {},
   "source": [
    "FACTORIZATION MACHINES CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "afa314b6-09c2-4d61-a678-273e626d50d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fm = FMClassifier(labelCol=\"cluster\", featuresCol=\"scaled_features\", stepSize=0.001)\n",
    "\n",
    "# # Train model.\n",
    "# fm_model = fm.fit(train_data)\n",
    "\n",
    "# # Make predictions.\n",
    "# fm_predictions =fm_model.transform(test_data)\n",
    "\n",
    "\n",
    "# # Select (prediction, true label) and compute test accuracy\n",
    "# fm_evaluator = MulticlassClassificationEvaluator(labelCol=\"cluster\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "# fm_accuracy = fm_evaluator.evaluate(fm_predictions)\n",
    "# print(\"Test set accuracy = %g\" % fm_accuracy)\n",
    "\n",
    "# # fmModel = model.stages[2]\n",
    "# # print(\"Factors: \" + str(fmModel.factors))  # type: ignore\n",
    "# # print(\"Linear: \" + str(fmModel.linear))  # type: ignore\n",
    "# # print(\"Intercept: \" + str(fmModel.intercept))  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b865983-5cfb-4149-9167-e2f2e0c6ae4f",
   "metadata": {},
   "source": [
    "If  dataset has highly imbalanced labels (e.g., 90% of the data belongs to one class), it may affect the model fitting process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0668a8-73b2-408e-8972-ba7d56549489",
   "metadata": {},
   "source": [
    "ONE-VS-REST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a6820812-be3d-4226-bdc6-21c4dd7f87c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 3: Instantiate Logistic Regression model\n",
    "# lr = LogisticRegression(featuresCol=\"scaled_features\", labelCol=\"cluster\", maxIter=10, tol=1E-6, fitIntercept=True)\n",
    "\n",
    "# # Step 4: Instantiate the OneVsRest classifier\n",
    "# ovr = OneVsRest(classifier=lr, labelCol=\"cluster\", featuresCol=\"scaled_features\")\n",
    "\n",
    "# ovr_model = ovr.fit(train_data)\n",
    "\n",
    "# # score the model on test data.\n",
    "# ovr_predictions = ovr_model.transform(test_data)\n",
    "\n",
    "# # Select (prediction, true label) and compute test accuracy\n",
    "# ovr_evaluator = MulticlassClassificationEvaluator(labelCol=\"cluster\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "# ovr_accuracy = ovr_evaluator.evaluate(ovr_predictions)\n",
    "# print(\"Test set accuracy = %g\" % ovr_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150ac3cf-3d18-42e5-8e82-d5d34afb22dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
